corpus_final = VCorpus(VectorSource(arquivo_tratado), readerControl = list(reader = readPlain, language = "eng"))
# Usando a função tm_map para executar as transformações
stopwords("portuguese")
# Removendo as stopwords e palavras sem sentido semântico pro objetivo final
# Retornar ao vetor "palavras" de forma iterativa, conforme ilustrado na Figura X, e ajustar os elementos
palavras = c("the", "ser", "silva", "nursing", "martinez", "martinez ", "francisco", "silva ", " silva", "Silva", "Martinez", "Francisco", "grande", "partir", "and", "uso", "utilização")
corpus_final = tm_map(corpus_final, removeWords, c(stopwords("portuguese"), palavras))
# Removendo o excesso de espaços em branco
corpus_final = tm_map(corpus_final, stripWhitespace)
# Removendo a pontuação
corpus_final = tm_map(corpus_final, removePunctuation)
# Removendo os números
corpus_final = tm_map(corpus_final, removeNumbers)
wordcloud(corpus_final, max.words = 20, random.order = T, colors = rainbow(8), rot.per = 0.5, use.r.layout = T)
wordcloud(matriz$word, matriz$freq, max.words = 20, random.order = T, colors = rainbow(8), rot.per = 0.5, use.r.layout = T)
wordcloud(corpus_final, max.words = 22, random.order = T, colors = rainbow(8), rot.per = 0.5, use.r.layout = T)
wordcloud(corpus_final, max.words = 22, random.order = T, colors = rainbow(8), rot.per = 0.5, use.r.layout = T)
wordcloud(corpus_final, max.words = 22, random.order = T, colors = rainbow(8), rot.per = 0.5, use.r.layout = T)
# Encontrando os termos mais frequentes, definindo como 10 o número mínimo de ocorrências
findFreqTerms(freq, 10, Inf)
# Encontrando os termos mais frequentes, definindo como 10 o número mínimo de ocorrências
findFreqTerms(freq, 8, Inf)
wordcloud(matriz$word, matriz$freq, max.words = 22, random.order = T, colors = rainbow(8), rot.per = 0.5, use.r.layout = T)
install.packages("ggplot2")
install.packages("plotly")
install.packages("neuralnet")
install.packages("mltools")
install.packages("data.table")
install.packages("caret", dependencies = T)
library(neuralnet)
library(mltools)
library(data.table)
library(caret)
iris2 = scale(iris[, 1:4])
iris2 = as.data.frame(iris2)
# Adiciona a classe
iris2$species = iris$Species
iris2
set.seed(1234)
particao = createDataPartition(1:dim(iris2)[1], p = .7)
iristreino = iris2[particao$Resample1, ]
iristeste = iris2[- particao$Resample1, ]
dim(iristreino)
dim(iristeste)
# Juntamos os atributos com a classe para não perdê-los
iristreino = cbind(iristreino[, 1:4], one_hot(as.data.table(iristreino[, 5])))
iristreino
modelo = neuralnet(V1_setosa + V1_versicolor + V1_virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, iristreino, hidden = c(5, 4))
print(modelo)
plot(modelo)
teste = compute(modelo, iristeste[, 1:4])
teste$net.result
resultado = as.data.frame(teste$net.result)
resultado
names(resultado)[1] <- 'setosa'
names(resultado)[2] <- 'versicolor'
names(resultado)[3] <- 'virginica'
resultado
resultado$class = colnames(resultado[, 1:3])[max.col(resultado[, 1:3], ties.method = 'first')]
resultado
confusao = table(resultado$class, iristeste$species)
confusao
sum(diag(confusao)*100/sum(confusao))
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_2.R', encoding = 'UTF-8', echo=TRUE)
funcao_geral <- function(operacao){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
operacao(coluna)
}
}
funcao_geral(mean)
View(a)
warnings()
# Separando os atributos numéricos
amostra
# Separando os atributos numéricos
amostra$genre <- NULL
funcao_geral <- function(){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
operacao(coluna)
}
}
funcao_geral <- function(operacao){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
operacao(coluna)
}
}
funcao_geral(mean)
funcao_geral <- function(operacao){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
print(operacao(coluna))
}
}
funcao_geral(mean)
funcao_geral <- function(){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
print(coluna)
}
}
funcao_geral()
amostra[instrumentalness]
amostra['instrumentalness']
mean(amostra['instrumentalness'])
mean(amostra['instrumentalness'][1:,])
mean(amostra['instrumentalness'])
amostra['instrumentalness']
amostra['instrumentalness'][2]
amostra['instrumentalness'][2,]
amostra['instrumentalness'][1:,]
amostra['instrumentalness'][,]
funcao_geral <- function(operation){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
print(operation(coluna[,]))
}
}
funcao_geral(mean)
# Análise de uma base de dados
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Separando os atributos numéricos
amostra$genre <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
operation(coluna[,])
}
}
funcao_geral(mean)
# Análise de uma base de dados
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Separando os atributos numéricos
amostra$genre <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
operation(coluna[,])
}
}
media <- funcao_geral(mean)
media
auxiliar_vector <- c()
funcao_geral <- function(operation){
# Criando o vetor de armazenamento dos resultados
auxiliar_vector <- c()
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
auxiliar_vector <- c(auxiliar_vector, operation(coluna[,]))
}
return(auxiliar_vector)
}
teste <- funcao_geral(mean)
teste
dados <- c(20.6, 21.1, 22.7, 22.2, 23.1, 20.9, 21.6, 21.8, 22.1, 22.9)
amplitude <- function(v) {
max(v) - min(v)
}
amplitude(dados)
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_2.R', encoding = 'UTF-8', echo=TRUE)
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_2.R', encoding = 'UTF-8', echo=TRUE)
dataframe
mediana
moda
a <- c(10,20,30,40)
a
linhas <- colnames(amostra)
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Eliminando o atributo categórico
amostra$genre <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
# Criando o vetor de armazenamento dos resultados
auxiliar_vector <- c()
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
auxiliar_vector <- c(auxiliar_vector, operation(coluna[,]))
}
return(auxiliar_vector)
}
# Construindo a função de cálculo de moda
moda <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Construindo a função de cálculo de amplitude
amplitude <- function(v) {
max(v) - min(v)
}
# Construindo a função de cálculo do erro padrão
erro_padrao <- function(v) {
desv_pad/sqrt(length(v))
}
linhas <- colnames(amostra)
# Análise de uma base de dados
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Eliminando o atributo categórico
amostra$genre <- NULL
amostra$X <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
# Criando o vetor de armazenamento dos resultados
auxiliar_vector <- c()
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
auxiliar_vector <- c(auxiliar_vector, operation(coluna[,]))
}
return(auxiliar_vector)
}
# Construindo a função de cálculo de moda
moda <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Construindo a função de cálculo de amplitude
amplitude <- function(v) {
max(v) - min(v)
}
# Construindo a função de cálculo do erro padrão
erro_padrao <- function(v) {
desv_pad/sqrt(length(v))
}
linhas <- colnames(amostra)
media <- funcao_geral(mean)
mediana <- funcao_geral(median)
moda <- funcao_geral(moda)
desv_pad <- funcao_geral(sd)
variancia <- funcao_geral(var)
err_pad <- funcao_geral(erro_padrao)
erro_padrao <- function(v) {
sd(v)/sqrt(length(v))
}
err_pad <- funcao_geral(erro_padrao)
amp <- funcao_geral(amplitude)
# Análise de uma base de dados
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Eliminando o atributo categórico
amostra$genre <- NULL
amostra$X <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
# Criando o vetor de armazenamento dos resultados
auxiliar_vector <- c()
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
auxiliar_vector <- c(auxiliar_vector, operation(coluna[,]))
}
return(auxiliar_vector)
}
# Construindo a função de cálculo de moda
moda <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Construindo a função de cálculo de amplitude
amplitude <- function(v) {
max(v) - min(v)
}
# Construindo a função de cálculo do erro padrão
erro_padrao <- function(v) {
sd(v)/sqrt(length(v))
}
# Construindo o dataset com as medidas
medidas <- c("Média", "Mediana", "Moda", "Desvio Padrão", "Variância", "Erro Padrão", "Amplitude")
linhas <- colnames(amostra)
media <- funcao_geral(mean)
mediana <- funcao_geral(median)
moda <- funcao_geral(moda)
desv_pad <- funcao_geral(sd)
variancia <- funcao_geral(var)
err_pad <- funcao_geral(erro_padrao)
amp <- funcao_geral(amplitude)
dataframe <- data.frame(linhas, media, mediana, moda, desv_pad, variancia, err_pad, amp)
dataframe
colnames(dataframe) <- medidas
dataframe
# Análise de uma base de dados
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Eliminando o atributo categórico
amostra$genre <- NULL
amostra$X <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
# Criando o vetor de armazenamento dos resultados
auxiliar_vector <- c()
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
auxiliar_vector <- c(auxiliar_vector, operation(coluna[,]))
}
return(auxiliar_vector)
}
# Construindo a função de cálculo de moda
moda <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Construindo a função de cálculo de amplitude
amplitude <- function(v) {
max(v) - min(v)
}
# Construindo a função de cálculo do erro padrão
erro_padrao <- function(v) {
sd(v)/sqrt(length(v))
}
# Construindo o dataset com as medidas
medidas <- c("Média", "Mediana", "Moda", "Desvio Padrão", "Variância", "Erro Padrão", "Amplitude")
features <- colnames(amostra)
media <- funcao_geral(mean)
mediana <- funcao_geral(median)
moda <- funcao_geral(moda)
desv_pad <- funcao_geral(sd)
variancia <- funcao_geral(var)
err_pad <- funcao_geral(erro_padrao)
amp <- funcao_geral(amplitude)
dataframe <- data.frame(linhas, media, mediana, moda, desv_pad, variancia, err_pad, amp)
colnames(dataframe) <- medidas
library(tidyr)
library(ggplot2)
# Construindo o histograma
dataframe %>% gather() %>% head()
# Construindo o histograma
dataframe %>% gather()
dataframe
# Análise de uma base de dados
# Importação das bibliotecas
library(tidyr)
library(ggplot2)
# Importação do dataset
dataset_list <- read.csv(file = "c:/Users/Usuario/Documents/Estudos/Data Science e Programação/Spotify API/playlists_songs_clusters.csv")
dataset <- as.data.frame(dataset_list)
# Selecionando uma amostra aleatória de 50 observações
amostra = dataset[sample(nrow(dataset), 50), ]
# Eliminando o atributo categórico
amostra$genre <- NULL
amostra$X <- NULL
# Construindo a função que irá realizar operações em cada coluna do dataset
funcao_geral <- function(operation){
# Criando o vetor de armazenamento dos resultados
auxiliar_vector <- c()
for (element in colnames(amostra)) {
# Selecionando a coluna de interesse
coluna <- amostra[element]
# Realizando a operação
auxiliar_vector <- c(auxiliar_vector, operation(coluna[,]))
}
return(auxiliar_vector)
}
# Construindo a função de cálculo de moda
moda <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Construindo a função de cálculo de amplitude
amplitude <- function(v) {
max(v) - min(v)
}
# Construindo a função de cálculo do erro padrão
erro_padrao <- function(v) {
sd(v)/sqrt(length(v))
}
# Construindo o dataset com as medidas
medidas <- c("Features", "Média", "Mediana", "Moda", "Desvio Padrão", "Variância", "Erro Padrão", "Amplitude")
features <- colnames(amostra)
media <- funcao_geral(mean)
mediana <- funcao_geral(median)
moda <- funcao_geral(moda)
desv_pad <- funcao_geral(sd)
variancia <- funcao_geral(var)
err_pad <- funcao_geral(erro_padrao)
amp <- funcao_geral(amplitude)
dataframe <- data.frame(linhas, media, mediana, moda, desv_pad, variancia, err_pad, amp)
colnames(dataframe) <- medidas
# Construindo o histograma
dataframe %>% gather()
ggplot(gather(dataframe), aes(value)) +
geom_histogram(bins = 20) +
facet_wrap(~key, scales = 'free_x')
dataframe %>% gather()
dataframe[2: ,] %>% gather()
ggplot(gather(dataframe), aes(value)) +
geom_histogram(bins = 20) +
facet_wrap(~key, scales = 'free_x')
dataframe[2: ,]
dataframe[c(2: ),]
dataframe[,(2:)]
dataframe[,(2: )]
dataframe[, 2:-1]
dataframe[2:]
tail(dataframe, -2)
dataframe_hist <- dataframe
dataframe_hist$Features <- NULL
dataframe_hist
dataframe
dataframe_hist
dataframe_hist %>% gather()
ggplot(gather(dataframe_hist), aes(value)) +
geom_histogram(bins = 20) +
facet_wrap(~key, scales = 'free_x')
dataframe_hist %>% gather()
ggplot(gather(dataframe_hist), aes(value)) +
geom_histogram(bins = 10) +
facet_wrap(~key, scales = 'free_x')
amostra
amostra %>% gather()
ggplot(gather(amostra), aes(value)) +
geom_histogram(bins = 10) +
facet_wrap(~key, scales = 'free_x')
install.packages(gridExtra)
install.packages('gridExtra')
library(gridExtra)
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset.png", height = 50*nrow(amostra), width = 200*ncol(amostra))
grid.table(amostra)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset.png", height = 2*nrow(amostra), width = 2*ncol(amostra))
grid.table(amostra)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset.png", height = 20*nrow(amostra), width = 100*ncol(amostra))
grid.table(amostra)
dev.off()
row.names(amostra) <- NULL
amostra
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset.png", height = 30*nrow(amostra), width = 80*ncol(amostra))
grid.table(amostra)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset.png", height = 25*nrow(amostra), width = 80*ncol(amostra))
grid.table(amostra)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset.png", height = 23*nrow(amostra), width = 75*ncol(amostra))
grid.table(amostra)
dev.off()
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_2.R', encoding = 'UTF-8', echo=TRUE)
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_2.R', encoding = 'UTF-8', echo=TRUE)
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset_medidas.png", height = 50*nrow(dataframe), width = 120*ncol(dataframe))
grid.table(dataframe)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset_medidas.png", height = 50*nrow(dataframe), width = 120*ncol(dataframe))
grid.table(dataframe)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset_medidas.png", height = 30*nrow(dataframe), width = 100*ncol(dataframe))
grid.table(dataframe)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset_medidas.png", height = 30*nrow(dataframe), width = 100*ncol(dataframe))
grid.table(dataframe)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset_medidas.png", height = 28*nrow(dataframe), width = 100*ncol(dataframe))
grid.table(dataframe)
dev.off()
png("c:/Users/Usuario/Documents/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Documentos/dataset_medidas.png", height = 25*nrow(dataframe), width = 100*ncol(dataframe))
grid.table(dataframe)
dev.off()
setwd("~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_1_V2.R', encoding = 'UTF-8', echo=TRUE)
mean(ComprimentoRaiz)
median(ComprimentoRaiz)
source('~/Mestrado/Disciplinas/FT087 - Planejamento e Análise Experimental/Códigos/Aula_01_Atividade_1.R', encoding = 'UTF-8', echo=TRUE)
print(moda)
moda <- getmode(dados)
moda
amplitude <- max(ComprimentoRaiz) - min(ComprimentoRaiz)
print(amplitude)
print(variancia)
print(desvioPadrao)
print (erroPadrao)
